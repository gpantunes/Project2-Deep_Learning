{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09621229-d756-4908-9564-93385bd4c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment.snake_game import SnakeGame\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import imageio # For video generation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "baf6f037-36c5-4308-8725-92fd45d8d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeHeuristic:\n",
    "    def __init__(self, game: SnakeGame):\n",
    "        self.game = game\n",
    "        # Map: game_direction_idx -> (row_change, col_change)\n",
    "        self.delta_coords = {\n",
    "            0: (-1, 0),  # Up\n",
    "            1: (0, 1),   # Right\n",
    "            2: (1, 0),   # Down\n",
    "            3: (0, -1)   # Left\n",
    "        }\n",
    "\n",
    "    def _get_closest_apple_pos(self):\n",
    "        if not self.game.apples:\n",
    "            return None\n",
    "        \n",
    "        head_r, head_c = self.game.snake[0]\n",
    "        closest_apple = None\n",
    "        min_dist = float('inf')\n",
    "\n",
    "        for apple_r, apple_c in self.game.apples:\n",
    "            dist = abs(apple_r - head_r) + abs(apple_c - head_c)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_apple = (apple_r, apple_c)\n",
    "        return closest_apple\n",
    "\n",
    "    def _is_safe_move(self, next_head_r, next_head_c):\n",
    "        if not (0 <= next_head_r < self.game.height and \\\n",
    "                0 <= next_head_c < self.game.width):\n",
    "            return False\n",
    "\n",
    "        if (next_head_r, next_head_c) in self.game.snake[1:]:\n",
    "            return False\n",
    "            \n",
    "        return True\n",
    "\n",
    "    def choose_action(self):\n",
    "        target_apple_pos = self._get_closest_apple_pos()\n",
    "\n",
    "        if target_apple_pos is None:\n",
    "            return 0\n",
    "\n",
    "        head_r, head_c = self.game.snake[0]\n",
    "        current_game_direction = self.game.direction\n",
    "\n",
    "        candidate_actions = []\n",
    "\n",
    "        for action_value in [-1, 0, 1]:\n",
    "            next_game_direction = (current_game_direction + action_value) % 4\n",
    "            if next_game_direction < 0: next_game_direction += 4\n",
    "\n",
    "            dr, dc = self.delta_coords[next_game_direction]\n",
    "\n",
    "            next_head_r, next_head_c = head_r + dr, head_c + dc\n",
    "\n",
    "            if self._is_safe_move(next_head_r, next_head_c):\n",
    "                dist_to_apple = abs(target_apple_pos[0] - next_head_r) + \\\n",
    "                                abs(target_apple_pos[1] - next_head_c)\n",
    "                candidate_actions.append({\n",
    "                    'action': action_value, \n",
    "                    'distance': dist_to_apple\n",
    "                })\n",
    "        \n",
    "        if not candidate_actions:\n",
    "            return 0\n",
    "\n",
    "        def sort_key(candidate):\n",
    "            action = candidate['action']\n",
    "            preference = 0\n",
    "            if action == 1: preference = 1\n",
    "            elif action == -1: preference = 2\n",
    "            return (candidate['distance'], preference)\n",
    "\n",
    "        candidate_actions.sort(key=sort_key)\n",
    "        \n",
    "        return candidate_actions[0]['action']\n",
    "\n",
    "    def play_game_and_record(self, max_steps: int, video_filename: str = \"snake_heuristic_game.gif\", fps: int = 5):\n",
    "        frames = []\n",
    "        history = {\n",
    "            'board': [],\n",
    "            'reward': [],\n",
    "            'done': -1,\n",
    "            'info': []\n",
    "        }\n",
    "        board_state, reward, done, info = self.game.reset()\n",
    "        \n",
    "        frames.append((board_state * 255).astype(np.uint8))\n",
    "\n",
    "        print(f\"Starting game with heuristic. Max steps: {max_steps}. Recording to {video_filename}\")\n",
    "\n",
    "        for step_num in range(max_steps):\n",
    "            history['board'].append(board_state)\n",
    "            history['reward'].append(reward)\n",
    "            history['info'].append(info)\n",
    "            if done:\n",
    "                history['done'] = step_num\n",
    "                print(f\"Game ended prematurely at step {step_num} before taking action. Score: {info['score']}\")\n",
    "                break\n",
    "\n",
    "            action_to_take = self.choose_action()\n",
    "            board_state, reward, done, info = self.game.step(action_to_take)\n",
    "            \n",
    "            frames.append((board_state * 255).astype(np.uint8))\n",
    "            \n",
    "            if (step_num + 1) % 100 == 0:\n",
    "                 print(f\"Step {step_num+1}/{max_steps}, Score: {info['score']}, Done: {done}\")\n",
    "\n",
    "\n",
    "            \"\"\"if done:\n",
    "                print(f\"Game over at step {step_num+1}. Final Score: {info['score']}\")\n",
    "                break\"\"\"\n",
    "        else:\n",
    "            print(f\"Game finished after {max_steps} steps (max_steps reached). Final Score: {self.game.score}\")\n",
    "\n",
    "        if frames:\n",
    "            print(f\"Saving video with {len(frames)} frames at {fps} FPS...\")\n",
    "            try:\n",
    "                imageio.mimsave(video_filename, frames, fps=fps)\n",
    "                print(f\"Video saved successfully as {video_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving video: {e}\")\n",
    "                print(\"Please ensure you have an imageio backend installed (e.g., 'pip install imageio[ffmpeg]' for MP4 or 'pip install imageio pillow' for GIF).\")\n",
    "        else:\n",
    "            print(\"No frames recorded.\")\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "027ca97c-a5d1-4f42-84c7-8435cd088967",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_WIDTH = 20\n",
    "GAME_HEIGHT = 20\n",
    "FOOD_AMOUNT = 1\n",
    "GRASS_GROWTH = 0.001\n",
    "MAX_GRASS = 0.05\n",
    "BORDER_SIZE = 1 # Add a visual border of 1 pixel\n",
    "MAX_GAME_STEPS = 500 # Set a limit for the game length\n",
    "VIDEO_FILENAME = \"snake_ai_player.gif\"\n",
    "FPS = 5 # Faster for smoother video\n",
    "\n",
    "class SnakeDQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(SnakeDQN, self).__init__()\n",
    "        C, H, W = input_shape\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(C, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        \n",
    "        dummy_input = torch.zeros(1, *input_shape)\n",
    "        conv_out_size = self.conv(dummy_input).view(1, -1).shape[1]\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "    \n",
    "def compute_loss(predicted_q_values, actions, target_q_values):\n",
    "    \"\"\"\n",
    "    predicted_q_values: [B, 3]\n",
    "    actions: [B]  (values in [0, 1, 2])\n",
    "    target_q_values: [B]\n",
    "    \"\"\"\n",
    "    action_indices = actions + 1\n",
    "    selected_q = predicted_q_values.gather(1, action_indices.unsqueeze(1)).squeeze(1)\n",
    "    return F.mse_loss(selected_q, target_q_values)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.05\n",
    "EPSILON_DECAY = 0.995\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "LEARNING_RATE = 1e-4\n",
    "TARGET_UPDATE_FREQ = 100\n",
    "EVAL_INTERVAL = 500  # Evaluate every N steps\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*samples)\n",
    "        return (\n",
    "            torch.tensor(np.array(states), dtype=torch.float32),\n",
    "            torch.tensor(actions, dtype=torch.int64),\n",
    "            torch.tensor(rewards, dtype=torch.float32),\n",
    "            torch.tensor(np.array(next_states), dtype=torch.float32),\n",
    "            torch.tensor(dones, dtype=torch.bool)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def train_dqn(game_class, max_train_steps=10000):\n",
    "    game = game_class(GAME_WIDTH, GAME_HEIGHT, FOOD_AMOUNT, BORDER_SIZE, GRASS_GROWTH, MAX_GRASS)\n",
    "    n_actions = 3\n",
    "\n",
    "    state = game.reset()[0]\n",
    "    state = np.transpose(state, (2, 0, 1))  # (C, H, W)\n",
    "    state_shape = state.shape\n",
    "    policy_net = SnakeDQN(state_shape, n_actions)\n",
    "    target_net = SnakeDQN(state_shape, n_actions)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "    replay_buffer = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "\n",
    "    epsilon = EPSILON_START\n",
    "    total_steps = 0\n",
    "\n",
    "    for episode in range(1, 10000):\n",
    "        state, _, done, _ = game.reset()\n",
    "        state = np.transpose(state, (2, 0, 1))\n",
    "        #state = np.expand_dims(state, axis=0)  # [1, H, W]\n",
    "\n",
    "        for _ in range(MAX_GAME_STEPS):\n",
    "            total_steps += 1\n",
    "\n",
    "            # Epsilon-greedy action selection\n",
    "            if random.random() < epsilon:\n",
    "                action = [-1, 0, 1][random.randint(0, 2)]\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "                    q_values = policy_net(state_tensor)\n",
    "                    action_idx = q_values.argmax().item()\n",
    "                    action = [-1, 0, 1][action_idx]\n",
    "\n",
    "            next_state, reward, done, info = game.step(action)\n",
    "            next_state = np.transpose(next_state, (2, 0, 1))\n",
    "            #next_state = np.expand_dims(next_state, axis=0)\n",
    "\n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            # Training step\n",
    "            if len(replay_buffer) >= BATCH_SIZE:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(BATCH_SIZE)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    next_q = target_net(next_states).max(1)[0]\n",
    "                    target_q = rewards + (1 - dones.float()) * GAMMA * next_q\n",
    "\n",
    "                predicted_q = policy_net(states)\n",
    "                loss = compute_loss(predicted_q, actions, target_q)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Update target network\n",
    "            if total_steps % TARGET_UPDATE_FREQ == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "            # Evaluation\n",
    "            if total_steps % EVAL_INTERVAL == 0:\n",
    "                print(f\"\\n=== Evaluation at Step {total_steps} ===\")\n",
    "                eval_game = game_class(GAME_WIDTH, GAME_HEIGHT, FOOD_AMOUNT, BORDER_SIZE, GRASS_GROWTH, MAX_GRASS)\n",
    "                heuristic = SnakeHeuristic(eval_game)\n",
    "                heuristic.play_game_and_record(MAX_GAME_STEPS, video_filename=f\"eval_step_{total_steps}.gif\", fps=FPS)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(EPSILON_END, epsilon * EPSILON_DECAY)\n",
    "\n",
    "        print(f\"Episode {episode}, Steps: {total_steps}, Epsilon: {epsilon:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81c099eb-13d2-4163-968d-13d0ca19ae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Steps: 16, Epsilon: 0.995\n",
      "Episode 2, Steps: 32, Epsilon: 0.990\n",
      "Episode 3, Steps: 78, Epsilon: 0.985\n",
      "Episode 4, Steps: 87, Epsilon: 0.980\n",
      "Episode 5, Steps: 92, Epsilon: 0.975\n",
      "Episode 6, Steps: 109, Epsilon: 0.970\n",
      "Episode 7, Steps: 120, Epsilon: 0.966\n",
      "Episode 8, Steps: 126, Epsilon: 0.961\n",
      "Episode 9, Steps: 169, Epsilon: 0.956\n",
      "Episode 10, Steps: 173, Epsilon: 0.951\n",
      "Episode 11, Steps: 177, Epsilon: 0.946\n",
      "Episode 12, Steps: 181, Epsilon: 0.942\n",
      "Episode 13, Steps: 186, Epsilon: 0.937\n",
      "Episode 14, Steps: 208, Epsilon: 0.932\n",
      "Episode 15, Steps: 219, Epsilon: 0.928\n",
      "Episode 16, Steps: 232, Epsilon: 0.923\n",
      "Episode 17, Steps: 237, Epsilon: 0.918\n",
      "Episode 18, Steps: 252, Epsilon: 0.914\n",
      "Episode 19, Steps: 255, Epsilon: 0.909\n",
      "Episode 20, Steps: 270, Epsilon: 0.905\n",
      "Episode 21, Steps: 283, Epsilon: 0.900\n",
      "Episode 22, Steps: 313, Epsilon: 0.896\n",
      "Episode 23, Steps: 343, Epsilon: 0.891\n",
      "Episode 24, Steps: 379, Epsilon: 0.887\n",
      "Episode 25, Steps: 384, Epsilon: 0.882\n",
      "Episode 26, Steps: 400, Epsilon: 0.878\n",
      "Episode 27, Steps: 406, Epsilon: 0.873\n",
      "Episode 28, Steps: 446, Epsilon: 0.869\n",
      "Episode 29, Steps: 452, Epsilon: 0.865\n",
      "Episode 30, Steps: 455, Epsilon: 0.860\n",
      "Episode 31, Steps: 463, Epsilon: 0.856\n",
      "Episode 32, Steps: 477, Epsilon: 0.852\n",
      "\n",
      "=== Evaluation at Step 500 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_500.gif\n",
      "Step 100/500, Score: 11.968000000000009, Done: False\n",
      "Game ended prematurely at step 163 before taking action. Score: 21.004000000000048\n",
      "Saving video with 164 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_500.gif\n",
      "Episode 33, Steps: 511, Epsilon: 0.848\n",
      "Episode 34, Steps: 549, Epsilon: 0.843\n",
      "Episode 35, Steps: 620, Epsilon: 0.839\n",
      "Episode 36, Steps: 623, Epsilon: 0.835\n",
      "Episode 37, Steps: 648, Epsilon: 0.831\n",
      "Episode 38, Steps: 673, Epsilon: 0.827\n",
      "Episode 39, Steps: 693, Epsilon: 0.822\n",
      "Episode 40, Steps: 696, Epsilon: 0.818\n",
      "Episode 41, Steps: 721, Epsilon: 0.814\n",
      "Episode 42, Steps: 747, Epsilon: 0.810\n",
      "Episode 43, Steps: 773, Epsilon: 0.806\n",
      "Episode 44, Steps: 796, Epsilon: 0.802\n",
      "Episode 45, Steps: 818, Epsilon: 0.798\n",
      "Episode 46, Steps: 828, Epsilon: 0.794\n",
      "Episode 47, Steps: 836, Epsilon: 0.790\n",
      "Episode 48, Steps: 851, Epsilon: 0.786\n",
      "Episode 49, Steps: 862, Epsilon: 0.782\n",
      "Episode 50, Steps: 881, Epsilon: 0.778\n",
      "Episode 51, Steps: 892, Epsilon: 0.774\n",
      "Episode 52, Steps: 926, Epsilon: 0.771\n",
      "Episode 53, Steps: 954, Epsilon: 0.767\n",
      "Episode 54, Steps: 973, Epsilon: 0.763\n",
      "\n",
      "=== Evaluation at Step 1000 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_1000.gif\n",
      "Step 100/500, Score: 12.96400000000002, Done: False\n",
      "Step 200/500, Score: 22.92200000000009, Done: False\n",
      "Step 300/500, Score: 34.51000000000002, Done: False\n",
      "Step 400/500, Score: 45.391999999999754, Done: False\n",
      "Step 500/500, Score: 54.37199999999948, Done: False\n",
      "Game finished after 500 steps (max_steps reached). Final Score: 54.37199999999948\n",
      "Saving video with 501 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_1000.gif\n",
      "Episode 55, Steps: 1014, Epsilon: 0.759\n",
      "Episode 56, Steps: 1074, Epsilon: 0.755\n",
      "Episode 57, Steps: 1087, Epsilon: 0.751\n",
      "Episode 58, Steps: 1109, Epsilon: 0.748\n",
      "Episode 59, Steps: 1122, Epsilon: 0.744\n",
      "Episode 60, Steps: 1137, Epsilon: 0.740\n",
      "Episode 61, Steps: 1151, Epsilon: 0.737\n",
      "Episode 62, Steps: 1176, Epsilon: 0.733\n",
      "Episode 63, Steps: 1192, Epsilon: 0.729\n",
      "Episode 64, Steps: 1216, Epsilon: 0.726\n",
      "Episode 65, Steps: 1224, Epsilon: 0.722\n",
      "Episode 66, Steps: 1235, Epsilon: 0.718\n",
      "Episode 67, Steps: 1247, Epsilon: 0.715\n",
      "Episode 68, Steps: 1260, Epsilon: 0.711\n",
      "Episode 69, Steps: 1278, Epsilon: 0.708\n",
      "Episode 70, Steps: 1295, Epsilon: 0.704\n",
      "Episode 71, Steps: 1309, Epsilon: 0.701\n",
      "Episode 72, Steps: 1316, Epsilon: 0.697\n",
      "Episode 73, Steps: 1319, Epsilon: 0.694\n",
      "Episode 74, Steps: 1361, Epsilon: 0.690\n",
      "Episode 75, Steps: 1436, Epsilon: 0.687\n",
      "Episode 76, Steps: 1475, Epsilon: 0.683\n",
      "\n",
      "=== Evaluation at Step 1500 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_1500.gif\n",
      "Step 100/500, Score: 12.828000000000019, Done: False\n",
      "Step 200/500, Score: 25.73400000000008, Done: False\n",
      "Step 300/500, Score: 35.43799999999999, Done: False\n",
      "Step 400/500, Score: 46.40199999999972, Done: False\n",
      "Step 500/500, Score: 56.29399999999944, Done: False\n",
      "Game finished after 500 steps (max_steps reached). Final Score: 56.29399999999944\n",
      "Saving video with 501 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_1500.gif\n",
      "Episode 77, Steps: 1500, Epsilon: 0.680\n",
      "Episode 78, Steps: 1543, Epsilon: 0.676\n",
      "Episode 79, Steps: 1550, Epsilon: 0.673\n",
      "Episode 80, Steps: 1585, Epsilon: 0.670\n",
      "Episode 81, Steps: 1600, Epsilon: 0.666\n",
      "Episode 82, Steps: 1620, Epsilon: 0.663\n",
      "Episode 83, Steps: 1634, Epsilon: 0.660\n",
      "Episode 84, Steps: 1726, Epsilon: 0.656\n",
      "Episode 85, Steps: 1739, Epsilon: 0.653\n",
      "Episode 86, Steps: 1789, Epsilon: 0.650\n",
      "Episode 87, Steps: 1810, Epsilon: 0.647\n",
      "Episode 88, Steps: 1836, Epsilon: 0.643\n",
      "Episode 89, Steps: 1872, Epsilon: 0.640\n",
      "Episode 90, Steps: 1883, Epsilon: 0.637\n",
      "Episode 91, Steps: 1895, Epsilon: 0.634\n",
      "Episode 92, Steps: 1906, Epsilon: 0.631\n",
      "Episode 93, Steps: 1947, Epsilon: 0.627\n",
      "Episode 94, Steps: 1983, Epsilon: 0.624\n",
      "\n",
      "=== Evaluation at Step 2000 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_2000.gif\n",
      "Step 100/500, Score: 12.988000000000019, Done: False\n",
      "Step 200/500, Score: 26.944000000000084, Done: False\n",
      "Step 300/500, Score: 36.795999999999964, Done: False\n",
      "Game ended prematurely at step 382 before taking action. Score: 46.791999999999746\n",
      "Saving video with 383 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_2000.gif\n",
      "Episode 95, Steps: 2025, Epsilon: 0.621\n",
      "Episode 96, Steps: 2035, Epsilon: 0.618\n",
      "Episode 97, Steps: 2051, Epsilon: 0.615\n",
      "Episode 98, Steps: 2063, Epsilon: 0.612\n",
      "Episode 99, Steps: 2085, Epsilon: 0.609\n",
      "Episode 100, Steps: 2110, Epsilon: 0.606\n",
      "Episode 101, Steps: 2126, Epsilon: 0.603\n",
      "Episode 102, Steps: 2169, Epsilon: 0.600\n",
      "Episode 103, Steps: 2201, Epsilon: 0.597\n",
      "Episode 104, Steps: 2228, Epsilon: 0.594\n",
      "Episode 105, Steps: 2231, Epsilon: 0.591\n",
      "Episode 106, Steps: 2238, Epsilon: 0.588\n",
      "Episode 107, Steps: 2267, Epsilon: 0.585\n",
      "Episode 108, Steps: 2312, Epsilon: 0.582\n",
      "Episode 109, Steps: 2331, Epsilon: 0.579\n",
      "Episode 110, Steps: 2393, Epsilon: 0.576\n",
      "Episode 111, Steps: 2412, Epsilon: 0.573\n",
      "Episode 112, Steps: 2437, Epsilon: 0.570\n",
      "Episode 113, Steps: 2458, Epsilon: 0.568\n",
      "Episode 114, Steps: 2491, Epsilon: 0.565\n",
      "\n",
      "=== Evaluation at Step 2500 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_2500.gif\n",
      "Step 100/500, Score: 11.92800000000002, Done: False\n",
      "Step 200/500, Score: 24.82200000000008, Done: False\n",
      "Step 300/500, Score: 38.801999999999964, Done: False\n",
      "Game ended prematurely at step 366 before taking action. Score: 46.97799999999982\n",
      "Saving video with 367 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_2500.gif\n",
      "Episode 115, Steps: 2533, Epsilon: 0.562\n",
      "Episode 116, Steps: 2553, Epsilon: 0.559\n",
      "Episode 117, Steps: 2568, Epsilon: 0.556\n",
      "Episode 118, Steps: 2589, Epsilon: 0.554\n",
      "Episode 119, Steps: 2619, Epsilon: 0.551\n",
      "Episode 120, Steps: 2637, Epsilon: 0.548\n",
      "Episode 121, Steps: 2666, Epsilon: 0.545\n",
      "Episode 122, Steps: 2742, Epsilon: 0.543\n",
      "Episode 123, Steps: 2789, Epsilon: 0.540\n",
      "Episode 124, Steps: 2808, Epsilon: 0.537\n",
      "Episode 125, Steps: 2812, Epsilon: 0.534\n",
      "Episode 126, Steps: 2847, Epsilon: 0.532\n",
      "Episode 127, Steps: 2858, Epsilon: 0.529\n",
      "Episode 128, Steps: 2869, Epsilon: 0.526\n",
      "Episode 129, Steps: 2890, Epsilon: 0.524\n",
      "Episode 130, Steps: 2950, Epsilon: 0.521\n",
      "Episode 131, Steps: 2967, Epsilon: 0.519\n",
      "Episode 132, Steps: 2972, Epsilon: 0.516\n",
      "\n",
      "=== Evaluation at Step 3000 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_3000.gif\n",
      "Step 100/500, Score: 13.75200000000002, Done: False\n",
      "Step 200/500, Score: 23.412000000000056, Done: False\n",
      "Game ended prematurely at step 266 before taking action. Score: 30.430000000000085\n",
      "Saving video with 267 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_3000.gif\n",
      "Episode 133, Steps: 3045, Epsilon: 0.513\n",
      "Episode 134, Steps: 3091, Epsilon: 0.511\n",
      "Episode 135, Steps: 3103, Epsilon: 0.508\n",
      "Episode 136, Steps: 3116, Epsilon: 0.506\n",
      "Episode 137, Steps: 3136, Epsilon: 0.503\n",
      "Episode 138, Steps: 3139, Epsilon: 0.501\n",
      "Episode 139, Steps: 3154, Epsilon: 0.498\n",
      "Episode 140, Steps: 3207, Epsilon: 0.496\n",
      "Episode 141, Steps: 3237, Epsilon: 0.493\n",
      "Episode 142, Steps: 3244, Epsilon: 0.491\n",
      "Episode 143, Steps: 3260, Epsilon: 0.488\n",
      "Episode 144, Steps: 3271, Epsilon: 0.486\n",
      "Episode 145, Steps: 3297, Epsilon: 0.483\n",
      "Episode 146, Steps: 3322, Epsilon: 0.481\n",
      "Episode 147, Steps: 3325, Epsilon: 0.479\n",
      "Episode 148, Steps: 3365, Epsilon: 0.476\n",
      "Episode 149, Steps: 3381, Epsilon: 0.474\n",
      "Episode 150, Steps: 3437, Epsilon: 0.471\n",
      "Episode 151, Steps: 3448, Epsilon: 0.469\n",
      "Episode 152, Steps: 3461, Epsilon: 0.467\n",
      "Episode 153, Steps: 3489, Epsilon: 0.464\n",
      "\n",
      "=== Evaluation at Step 3500 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_3500.gif\n",
      "Step 100/500, Score: 12.856000000000016, Done: False\n",
      "Step 200/500, Score: 23.748000000000076, Done: False\n",
      "Game ended prematurely at step 224 before taking action. Score: 27.898000000000092\n",
      "Saving video with 225 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_3500.gif\n",
      "Episode 154, Steps: 3506, Epsilon: 0.462\n",
      "Episode 155, Steps: 3512, Epsilon: 0.460\n",
      "Episode 156, Steps: 3576, Epsilon: 0.458\n",
      "Episode 157, Steps: 3581, Epsilon: 0.455\n",
      "Episode 158, Steps: 3614, Epsilon: 0.453\n",
      "Episode 159, Steps: 3663, Epsilon: 0.451\n",
      "Episode 160, Steps: 3675, Epsilon: 0.448\n",
      "Episode 161, Steps: 3704, Epsilon: 0.446\n",
      "Episode 162, Steps: 3753, Epsilon: 0.444\n",
      "Episode 163, Steps: 3800, Epsilon: 0.442\n",
      "Episode 164, Steps: 3839, Epsilon: 0.440\n",
      "Episode 165, Steps: 3945, Epsilon: 0.437\n",
      "Episode 166, Steps: 3964, Epsilon: 0.435\n",
      "Episode 167, Steps: 3988, Epsilon: 0.433\n",
      "\n",
      "=== Evaluation at Step 4000 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_4000.gif\n",
      "Step 100/500, Score: 11.97000000000002, Done: False\n",
      "Step 200/500, Score: 25.97000000000009, Done: False\n",
      "Step 300/500, Score: 35.85400000000002, Done: False\n",
      "Step 400/500, Score: 47.76599999999976, Done: False\n",
      "Step 500/500, Score: 57.73599999999948, Done: False\n",
      "Game finished after 500 steps (max_steps reached). Final Score: 57.73599999999948\n",
      "Saving video with 501 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_4000.gif\n",
      "Episode 168, Steps: 4011, Epsilon: 0.431\n",
      "Episode 169, Steps: 4040, Epsilon: 0.429\n",
      "Episode 170, Steps: 4076, Epsilon: 0.427\n",
      "Episode 171, Steps: 4094, Epsilon: 0.424\n",
      "Episode 172, Steps: 4099, Epsilon: 0.422\n",
      "Episode 173, Steps: 4115, Epsilon: 0.420\n",
      "Episode 174, Steps: 4187, Epsilon: 0.418\n",
      "Episode 175, Steps: 4205, Epsilon: 0.416\n",
      "Episode 176, Steps: 4238, Epsilon: 0.414\n",
      "Episode 177, Steps: 4301, Epsilon: 0.412\n",
      "Episode 178, Steps: 4315, Epsilon: 0.410\n",
      "Episode 179, Steps: 4340, Epsilon: 0.408\n",
      "Episode 180, Steps: 4366, Epsilon: 0.406\n",
      "Episode 181, Steps: 4375, Epsilon: 0.404\n",
      "Episode 182, Steps: 4430, Epsilon: 0.402\n",
      "Episode 183, Steps: 4435, Epsilon: 0.400\n",
      "Episode 184, Steps: 4469, Epsilon: 0.398\n",
      "\n",
      "=== Evaluation at Step 4500 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_4500.gif\n",
      "Step 100/500, Score: 11.000000000000004, Done: False\n",
      "Step 200/500, Score: 22.968000000000064, Done: False\n",
      "Step 300/500, Score: 34.934000000000005, Done: False\n",
      "Step 400/500, Score: 45.93399999999972, Done: False\n",
      "Step 500/500, Score: 53.90599999999945, Done: False\n",
      "Game finished after 500 steps (max_steps reached). Final Score: 53.90599999999945\n",
      "Saving video with 501 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_4500.gif\n",
      "Episode 185, Steps: 4532, Epsilon: 0.396\n",
      "Episode 186, Steps: 4638, Epsilon: 0.394\n",
      "Episode 187, Steps: 4661, Epsilon: 0.392\n",
      "Episode 188, Steps: 4711, Epsilon: 0.390\n",
      "Episode 189, Steps: 4739, Epsilon: 0.388\n",
      "Episode 190, Steps: 4749, Epsilon: 0.386\n",
      "Episode 191, Steps: 4791, Epsilon: 0.384\n",
      "Episode 192, Steps: 4796, Epsilon: 0.382\n",
      "Episode 193, Steps: 4846, Epsilon: 0.380\n",
      "Episode 194, Steps: 4856, Epsilon: 0.378\n",
      "Episode 195, Steps: 4909, Epsilon: 0.376\n",
      "Episode 196, Steps: 4925, Epsilon: 0.374\n",
      "Episode 197, Steps: 4960, Epsilon: 0.373\n",
      "Episode 198, Steps: 4990, Epsilon: 0.371\n",
      "\n",
      "=== Evaluation at Step 5000 ===\n",
      "Starting game with heuristic. Max steps: 500. Recording to eval_step_5000.gif\n",
      "Step 100/500, Score: 12.84600000000001, Done: False\n",
      "Step 200/500, Score: 24.78800000000008, Done: False\n",
      "Game ended prematurely at step 208 before taking action. Score: 26.10200000000008\n",
      "Saving video with 209 frames at 5 FPS...\n",
      "Video saved successfully as eval_step_5000.gif\n",
      "Episode 199, Steps: 5020, Epsilon: 0.369\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m game_instance = SnakeGame(\n\u001b[32m      2\u001b[39m     width=GAME_WIDTH, \n\u001b[32m      3\u001b[39m     height=GAME_HEIGHT, \n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     grass_growth=GRASS_GROWTH, \n\u001b[32m      7\u001b[39m     max_grass=MAX_GRASS)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSnakeGame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m heuristic_player = SnakeHeuristic(game=game_instance)\n\u001b[32m     13\u001b[39m history = heuristic_player.play_game_and_record(max_steps=MAX_GAME_STEPS, \n\u001b[32m     14\u001b[39m                                           video_filename=VIDEO_FILENAME, \n\u001b[32m     15\u001b[39m                                           fps=FPS)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36mtrain_dqn\u001b[39m\u001b[34m(game_class, max_train_steps)\u001b[39m\n\u001b[32m    126\u001b[39m states, actions, rewards, next_states, dones = replay_buffer.sample(BATCH_SIZE)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     next_q = \u001b[43mtarget_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_states\u001b[49m\u001b[43m)\u001b[49m.max(\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    130\u001b[39m     target_q = rewards + (\u001b[32m1\u001b[39m - dones.float()) * GAMMA * next_q\n\u001b[32m    132\u001b[39m predicted_q = policy_net(states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mSnakeDQN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     x = x.view(x.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_workspace/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "game_instance = SnakeGame(\n",
    "    width=GAME_WIDTH, \n",
    "    height=GAME_HEIGHT, \n",
    "    food_amount=FOOD_AMOUNT, \n",
    "    border=BORDER_SIZE, \n",
    "    grass_growth=GRASS_GROWTH, \n",
    "    max_grass=MAX_GRASS)\n",
    "\n",
    "train_dqn(SnakeGame)\n",
    "\n",
    "heuristic_player = SnakeHeuristic(game=game_instance)\n",
    "\n",
    "history = heuristic_player.play_game_and_record(max_steps=MAX_GAME_STEPS, \n",
    "                                          video_filename=VIDEO_FILENAME, \n",
    "                                          fps=FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31906eac-adac-419e-8550-bee9b0c738c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0},\n",
       " {'score': np.float64(0.05)},\n",
       " {'score': np.float64(0.1)},\n",
       " {'score': np.float64(0.15000000000000002)},\n",
       " {'score': np.float64(0.2)},\n",
       " {'score': np.float64(0.25)},\n",
       " {'score': np.float64(0.3)},\n",
       " {'score': np.float64(0.35)},\n",
       " {'score': np.float64(0.39999999999999997)},\n",
       " {'score': np.float64(0.44999999999999996)},\n",
       " {'score': np.float64(0.49999999999999994)},\n",
       " {'score': np.float64(0.5499999999999999)},\n",
       " {'score': np.float64(0.6)},\n",
       " {'score': np.float64(0.65)},\n",
       " {'score': np.float64(0.7000000000000001)},\n",
       " {'score': np.float64(1.75)},\n",
       " {'score': np.float64(1.8)},\n",
       " {'score': np.float64(1.85)},\n",
       " {'score': np.float64(1.9000000000000001)},\n",
       " {'score': np.float64(1.9500000000000002)},\n",
       " {'score': np.float64(2.0)},\n",
       " {'score': np.float64(3.05)},\n",
       " {'score': np.float64(3.0999999999999996)},\n",
       " {'score': np.float64(3.1499999999999995)},\n",
       " {'score': np.float64(3.1999999999999993)},\n",
       " {'score': np.float64(3.249999999999999)},\n",
       " {'score': np.float64(3.299999999999999)},\n",
       " {'score': np.float64(4.349999999999999)},\n",
       " {'score': np.float64(5.399999999999999)},\n",
       " {'score': np.float64(5.449999999999998)},\n",
       " {'score': np.float64(5.499999999999998)},\n",
       " {'score': np.float64(5.549999999999998)},\n",
       " {'score': np.float64(5.599999999999998)},\n",
       " {'score': np.float64(5.649999999999998)},\n",
       " {'score': np.float64(5.6999999999999975)},\n",
       " {'score': np.float64(5.749999999999997)},\n",
       " {'score': np.float64(5.773999999999997)},\n",
       " {'score': np.float64(5.823999999999997)},\n",
       " {'score': np.float64(6.873999999999997)},\n",
       " {'score': np.float64(6.923999999999997)},\n",
       " {'score': np.float64(6.973999999999997)},\n",
       " {'score': np.float64(7.0239999999999965)},\n",
       " {'score': np.float64(7.073999999999996)},\n",
       " {'score': np.float64(7.123999999999996)},\n",
       " {'score': np.float64(8.173999999999996)},\n",
       " {'score': np.float64(8.223999999999997)},\n",
       " {'score': np.float64(8.273999999999997)},\n",
       " {'score': np.float64(8.323999999999998)},\n",
       " {'score': np.float64(8.373999999999999)},\n",
       " {'score': np.float64(8.424)},\n",
       " {'score': np.float64(8.474)},\n",
       " {'score': np.float64(8.524000000000001)},\n",
       " {'score': np.float64(8.574000000000002)},\n",
       " {'score': np.float64(8.624000000000002)},\n",
       " {'score': np.float64(8.674000000000003)},\n",
       " {'score': np.float64(8.724000000000004)},\n",
       " {'score': np.float64(8.774000000000004)},\n",
       " {'score': np.float64(8.824000000000005)},\n",
       " {'score': np.float64(8.874000000000006)},\n",
       " {'score': np.float64(8.924000000000007)},\n",
       " {'score': np.float64(8.974000000000007)},\n",
       " {'score': np.float64(9.024000000000008)},\n",
       " {'score': np.float64(10.074000000000009)},\n",
       " {'score': np.float64(10.12400000000001)},\n",
       " {'score': np.float64(10.17400000000001)},\n",
       " {'score': np.float64(10.22400000000001)},\n",
       " {'score': np.float64(10.274000000000012)},\n",
       " {'score': np.float64(10.324000000000012)},\n",
       " {'score': np.float64(10.366000000000012)},\n",
       " {'score': np.float64(10.416000000000013)},\n",
       " {'score': np.float64(10.466000000000014)},\n",
       " {'score': np.float64(10.516000000000014)},\n",
       " {'score': np.float64(10.566000000000015)},\n",
       " {'score': np.float64(10.616000000000016)},\n",
       " {'score': np.float64(10.666000000000016)},\n",
       " {'score': np.float64(10.716000000000017)},\n",
       " {'score': np.float64(10.766000000000018)},\n",
       " {'score': np.float64(10.804000000000018)},\n",
       " {'score': np.float64(10.854000000000019)},\n",
       " {'score': np.float64(10.90400000000002)},\n",
       " {'score': np.float64(10.95400000000002)},\n",
       " {'score': np.float64(11.00400000000002)},\n",
       " {'score': np.float64(11.054000000000022)},\n",
       " {'score': np.float64(11.104000000000022)},\n",
       " {'score': np.float64(11.154000000000023)},\n",
       " {'score': np.float64(11.204000000000024)},\n",
       " {'score': np.float64(12.254000000000024)},\n",
       " {'score': np.float64(12.304000000000025)},\n",
       " {'score': np.float64(12.354000000000026)},\n",
       " {'score': np.float64(12.404000000000027)},\n",
       " {'score': np.float64(12.454000000000027)},\n",
       " {'score': np.float64(12.504000000000028)},\n",
       " {'score': np.float64(12.554000000000029)},\n",
       " {'score': np.float64(12.60400000000003)},\n",
       " {'score': np.float64(12.65400000000003)},\n",
       " {'score': np.float64(12.70400000000003)},\n",
       " {'score': np.float64(12.754000000000032)},\n",
       " {'score': np.float64(12.804000000000032)},\n",
       " {'score': np.float64(12.854000000000033)},\n",
       " {'score': np.float64(12.904000000000034)},\n",
       " {'score': np.float64(12.954000000000034)},\n",
       " {'score': np.float64(13.004000000000035)},\n",
       " {'score': np.float64(13.054000000000036)},\n",
       " {'score': np.float64(13.104000000000037)},\n",
       " {'score': np.float64(13.154000000000037)},\n",
       " {'score': np.float64(13.204000000000038)},\n",
       " {'score': np.float64(14.254000000000039)},\n",
       " {'score': np.float64(14.30400000000004)},\n",
       " {'score': np.float64(14.35400000000004)},\n",
       " {'score': np.float64(14.40400000000004)},\n",
       " {'score': np.float64(14.454000000000041)},\n",
       " {'score': np.float64(14.504000000000042)},\n",
       " {'score': np.float64(14.554000000000043)},\n",
       " {'score': np.float64(14.604000000000044)},\n",
       " {'score': np.float64(14.654000000000044)},\n",
       " {'score': np.float64(14.704000000000045)},\n",
       " {'score': np.float64(14.754000000000046)},\n",
       " {'score': np.float64(14.804000000000046)},\n",
       " {'score': np.float64(14.854000000000047)},\n",
       " {'score': np.float64(14.904000000000048)},\n",
       " {'score': np.float64(14.954000000000049)},\n",
       " {'score': np.float64(16.004000000000048)},\n",
       " {'score': np.float64(16.05400000000005)},\n",
       " {'score': np.float64(16.10400000000005)},\n",
       " {'score': np.float64(16.15400000000005)},\n",
       " {'score': np.float64(16.20400000000005)},\n",
       " {'score': np.float64(16.25400000000005)},\n",
       " {'score': np.float64(16.304000000000052)},\n",
       " {'score': np.float64(16.354000000000052)},\n",
       " {'score': np.float64(16.404000000000053)},\n",
       " {'score': np.float64(16.454000000000054)},\n",
       " {'score': np.float64(16.504000000000055)},\n",
       " {'score': np.float64(16.554000000000055)},\n",
       " {'score': np.float64(16.604000000000056)},\n",
       " {'score': np.float64(16.654000000000057)},\n",
       " {'score': np.float64(16.704000000000057)},\n",
       " {'score': np.float64(16.754000000000058)},\n",
       " {'score': np.float64(16.80400000000006)},\n",
       " {'score': np.float64(17.85400000000006)},\n",
       " {'score': np.float64(17.90400000000006)},\n",
       " {'score': np.float64(17.95400000000006)},\n",
       " {'score': np.float64(18.00400000000006)},\n",
       " {'score': np.float64(18.054000000000062)},\n",
       " {'score': np.float64(18.104000000000063)},\n",
       " {'score': np.float64(18.154000000000064)},\n",
       " {'score': np.float64(18.204000000000065)},\n",
       " {'score': np.float64(18.254000000000065)},\n",
       " {'score': np.float64(18.304000000000066)},\n",
       " {'score': np.float64(18.354000000000067)},\n",
       " {'score': np.float64(18.390000000000068)},\n",
       " {'score': np.float64(18.42600000000007)},\n",
       " {'score': np.float64(18.46200000000007)},\n",
       " {'score': np.float64(18.498000000000072)},\n",
       " {'score': np.float64(18.534000000000074)},\n",
       " {'score': np.float64(18.570000000000075)},\n",
       " {'score': np.float64(18.606000000000076)},\n",
       " {'score': np.float64(18.642000000000078)},\n",
       " {'score': np.float64(18.69200000000008)},\n",
       " {'score': np.float64(19.74200000000008)},\n",
       " {'score': np.float64(19.79200000000008)},\n",
       " {'score': np.float64(19.84200000000008)},\n",
       " {'score': np.float64(19.89200000000008)},\n",
       " {'score': np.float64(19.942000000000082)},\n",
       " {'score': np.float64(19.992000000000083)},\n",
       " {'score': np.float64(20.042000000000083)},\n",
       " {'score': np.float64(20.092000000000084)},\n",
       " {'score': np.float64(20.142000000000085)},\n",
       " {'score': np.float64(20.192000000000085)},\n",
       " {'score': np.float64(20.242000000000086)},\n",
       " {'score': np.float64(20.292000000000087)},\n",
       " {'score': np.float64(20.332000000000086)},\n",
       " {'score': np.float64(20.382000000000087)},\n",
       " {'score': np.float64(20.432000000000087)},\n",
       " {'score': np.float64(20.482000000000088)},\n",
       " {'score': np.float64(20.53200000000009)},\n",
       " {'score': np.float64(21.58200000000009)},\n",
       " {'score': np.float64(21.63200000000009)},\n",
       " {'score': np.float64(21.68200000000009)},\n",
       " {'score': np.float64(21.73200000000009)},\n",
       " {'score': np.float64(21.782000000000092)},\n",
       " {'score': np.float64(21.832000000000093)},\n",
       " {'score': np.float64(22.882000000000094)},\n",
       " {'score': np.float64(22.932000000000095)},\n",
       " {'score': np.float64(22.982000000000095)},\n",
       " {'score': np.float64(23.032000000000096)},\n",
       " {'score': np.float64(23.082000000000097)},\n",
       " {'score': np.float64(23.132000000000097)},\n",
       " {'score': np.float64(23.182000000000098)},\n",
       " {'score': np.float64(23.2320000000001)},\n",
       " {'score': np.float64(23.2820000000001)},\n",
       " {'score': np.float64(23.3020000000001)},\n",
       " {'score': np.float64(23.3520000000001)},\n",
       " {'score': np.float64(23.4020000000001)},\n",
       " {'score': np.float64(23.4520000000001)},\n",
       " {'score': np.float64(23.502000000000102)},\n",
       " {'score': np.float64(23.552000000000103)},\n",
       " {'score': np.float64(23.602000000000103)},\n",
       " {'score': np.float64(23.652000000000104)},\n",
       " {'score': np.float64(23.702000000000105)},\n",
       " {'score': np.float64(24.752000000000105)},\n",
       " {'score': np.float64(24.802000000000106)},\n",
       " {'score': np.float64(24.852000000000107)},\n",
       " {'score': np.float64(24.902000000000108)},\n",
       " {'score': np.float64(24.95200000000011)},\n",
       " {'score': np.float64(25.00200000000011)},\n",
       " {'score': np.float64(25.05200000000011)},\n",
       " {'score': np.float64(25.10200000000011)},\n",
       " {'score': np.float64(25.138000000000112)},\n",
       " {'score': np.float64(25.174000000000113)},\n",
       " {'score': np.float64(25.224000000000114)},\n",
       " {'score': np.float64(25.274000000000115)},\n",
       " {'score': np.float64(25.324000000000115)},\n",
       " {'score': np.float64(25.374000000000116)},\n",
       " {'score': np.float64(25.424000000000117)},\n",
       " {'score': np.float64(25.474000000000117)},\n",
       " {'score': np.float64(25.524000000000118)},\n",
       " {'score': np.float64(25.57400000000012)},\n",
       " {'score': np.float64(25.62400000000012)},\n",
       " {'score': np.float64(25.67400000000012)},\n",
       " {'score': np.float64(25.72400000000012)},\n",
       " {'score': np.float64(25.77400000000012)},\n",
       " {'score': np.float64(25.824000000000122)},\n",
       " {'score': np.float64(25.874000000000123)},\n",
       " {'score': np.float64(25.924000000000124)},\n",
       " {'score': np.float64(25.974000000000125)},\n",
       " {'score': np.float64(26.024000000000125)},\n",
       " {'score': np.float64(26.074000000000126)},\n",
       " {'score': np.float64(26.124000000000127)},\n",
       " {'score': np.float64(26.174000000000127)},\n",
       " {'score': np.float64(27.224000000000128)},\n",
       " {'score': np.float64(27.27400000000013)},\n",
       " {'score': np.float64(27.32400000000013)},\n",
       " {'score': np.float64(27.37400000000013)},\n",
       " {'score': np.float64(27.42400000000013)},\n",
       " {'score': np.float64(27.47400000000013)},\n",
       " {'score': np.float64(27.524000000000132)},\n",
       " {'score': np.float64(27.574000000000133)},\n",
       " {'score': np.float64(27.624000000000134)},\n",
       " {'score': np.float64(27.674000000000134)},\n",
       " {'score': np.float64(27.724000000000135)},\n",
       " {'score': np.float64(27.774000000000136)},\n",
       " {'score': np.float64(27.824000000000137)},\n",
       " {'score': np.float64(27.874000000000137)},\n",
       " {'score': np.float64(27.924000000000138)},\n",
       " {'score': np.float64(28.97400000000014)},\n",
       " {'score': np.float64(29.02400000000014)},\n",
       " {'score': np.float64(29.07400000000014)},\n",
       " {'score': np.float64(29.12400000000014)},\n",
       " {'score': np.float64(29.17400000000014)},\n",
       " {'score': np.float64(29.224000000000142)},\n",
       " {'score': np.float64(29.274000000000143)},\n",
       " {'score': np.float64(29.324000000000144)},\n",
       " {'score': np.float64(29.374000000000144)},\n",
       " {'score': np.float64(30.424000000000145)},\n",
       " {'score': np.float64(30.474000000000146)},\n",
       " {'score': np.float64(30.524000000000147)},\n",
       " {'score': np.float64(30.574000000000147)},\n",
       " {'score': np.float64(30.624000000000148)},\n",
       " {'score': np.float64(30.67400000000015)},\n",
       " {'score': np.float64(30.71800000000015)},\n",
       " {'score': np.float64(30.76800000000015)},\n",
       " {'score': np.float64(30.81800000000015)},\n",
       " {'score': np.float64(30.86800000000015)},\n",
       " {'score': np.float64(30.918000000000152)},\n",
       " {'score': np.float64(30.968000000000153)},\n",
       " {'score': np.float64(31.018000000000153)},\n",
       " {'score': np.float64(31.068000000000154)},\n",
       " {'score': np.float64(31.118000000000155)},\n",
       " {'score': np.float64(31.168000000000156)},\n",
       " {'score': np.float64(31.218000000000156)},\n",
       " {'score': np.float64(31.268000000000157)},\n",
       " {'score': np.float64(31.318000000000158)},\n",
       " {'score': np.float64(31.356000000000158)},\n",
       " {'score': np.float64(32.406000000000155)},\n",
       " {'score': np.float64(32.45600000000015)},\n",
       " {'score': np.float64(32.50600000000015)},\n",
       " {'score': np.float64(32.55600000000015)},\n",
       " {'score': np.float64(32.606000000000144)},\n",
       " {'score': np.float64(32.65600000000014)},\n",
       " {'score': np.float64(32.70600000000014)},\n",
       " {'score': np.float64(32.756000000000135)},\n",
       " {'score': np.float64(33.80600000000013)},\n",
       " {'score': np.float64(33.85600000000013)},\n",
       " {'score': np.float64(33.89800000000013)},\n",
       " {'score': np.float64(33.94800000000013)},\n",
       " {'score': np.float64(33.998000000000125)},\n",
       " {'score': np.float64(34.04800000000012)},\n",
       " {'score': np.float64(34.09800000000012)},\n",
       " {'score': np.float64(34.14800000000012)},\n",
       " {'score': np.float64(34.17800000000012)},\n",
       " {'score': np.float64(34.228000000000115)},\n",
       " {'score': np.float64(34.27800000000011)},\n",
       " {'score': np.float64(34.32800000000011)},\n",
       " {'score': np.float64(34.37800000000011)},\n",
       " {'score': np.float64(34.428000000000104)},\n",
       " {'score': np.float64(34.4780000000001)},\n",
       " {'score': np.float64(34.5280000000001)},\n",
       " {'score': np.float64(34.578000000000095)},\n",
       " {'score': np.float64(34.62800000000009)},\n",
       " {'score': np.float64(35.67800000000009)},\n",
       " {'score': np.float64(35.72800000000009)},\n",
       " {'score': np.float64(35.778000000000084)},\n",
       " {'score': np.float64(35.82800000000008)},\n",
       " {'score': np.float64(35.87800000000008)},\n",
       " {'score': np.float64(35.928000000000075)},\n",
       " {'score': np.float64(35.97800000000007)},\n",
       " {'score': np.float64(36.02800000000007)},\n",
       " {'score': np.float64(36.07800000000007)},\n",
       " {'score': np.float64(36.128000000000064)},\n",
       " {'score': np.float64(36.17800000000006)},\n",
       " {'score': np.float64(36.22800000000006)},\n",
       " {'score': np.float64(36.278000000000056)},\n",
       " {'score': np.float64(36.32800000000005)},\n",
       " {'score': np.float64(36.37800000000005)},\n",
       " {'score': np.float64(36.42800000000005)},\n",
       " {'score': np.float64(36.478000000000044)},\n",
       " {'score': np.float64(36.52800000000004)},\n",
       " {'score': np.float64(36.57800000000004)},\n",
       " {'score': np.float64(36.628000000000036)},\n",
       " {'score': np.float64(36.67800000000003)},\n",
       " {'score': np.float64(36.72800000000003)},\n",
       " {'score': np.float64(36.77800000000003)},\n",
       " {'score': np.float64(36.828000000000024)},\n",
       " {'score': np.float64(36.87800000000002)},\n",
       " {'score': np.float64(36.92800000000002)},\n",
       " {'score': np.float64(36.978000000000016)},\n",
       " {'score': np.float64(37.02800000000001)},\n",
       " {'score': np.float64(37.07800000000001)},\n",
       " {'score': np.float64(37.12800000000001)},\n",
       " {'score': np.float64(38.178000000000004)},\n",
       " {'score': np.float64(38.228)},\n",
       " {'score': np.float64(38.278)},\n",
       " {'score': np.float64(38.327999999999996)},\n",
       " {'score': np.float64(38.37799999999999)},\n",
       " {'score': np.float64(38.42799999999999)},\n",
       " {'score': np.float64(38.47799999999999)},\n",
       " {'score': np.float64(38.527999999999984)},\n",
       " {'score': np.float64(38.57799999999998)},\n",
       " {'score': np.float64(38.62799999999998)},\n",
       " {'score': np.float64(38.677999999999976)},\n",
       " {'score': np.float64(38.72799999999997)},\n",
       " {'score': np.float64(38.77799999999997)},\n",
       " {'score': np.float64(38.82799999999997)},\n",
       " {'score': np.float64(38.877999999999965)},\n",
       " {'score': np.float64(38.92799999999996)},\n",
       " {'score': np.float64(38.97799999999996)},\n",
       " {'score': np.float64(40.027999999999956)},\n",
       " {'score': np.float64(40.07799999999995)},\n",
       " {'score': np.float64(40.12799999999995)},\n",
       " {'score': np.float64(40.17799999999995)},\n",
       " {'score': np.float64(40.227999999999945)},\n",
       " {'score': np.float64(40.27799999999994)},\n",
       " {'score': np.float64(40.32799999999994)},\n",
       " {'score': np.float64(40.377999999999936)},\n",
       " {'score': np.float64(40.42799999999993)},\n",
       " {'score': np.float64(40.47799999999993)},\n",
       " {'score': np.float64(40.52799999999993)},\n",
       " {'score': np.float64(40.577999999999925)},\n",
       " {'score': np.float64(40.62799999999992)},\n",
       " {'score': np.float64(40.67799999999992)},\n",
       " {'score': np.float64(40.727999999999916)},\n",
       " {'score': np.float64(40.77799999999991)},\n",
       " {'score': np.float64(40.82799999999991)},\n",
       " {'score': np.float64(40.87799999999991)},\n",
       " {'score': np.float64(40.927999999999905)},\n",
       " {'score': np.float64(40.9779999999999)},\n",
       " {'score': np.float64(41.0279999999999)},\n",
       " {'score': np.float64(41.077999999999896)},\n",
       " {'score': np.float64(41.12799999999989)},\n",
       " {'score': np.float64(41.17799999999989)},\n",
       " {'score': np.float64(42.22799999999989)},\n",
       " {'score': np.float64(42.277999999999885)},\n",
       " {'score': np.float64(42.32799999999988)},\n",
       " {'score': np.float64(42.37799999999988)},\n",
       " {'score': np.float64(42.42799999999988)},\n",
       " {'score': np.float64(42.477999999999874)},\n",
       " {'score': np.float64(42.52799999999987)},\n",
       " {'score': np.float64(42.57799999999987)},\n",
       " {'score': np.float64(42.627999999999865)},\n",
       " {'score': np.float64(42.67799999999986)},\n",
       " {'score': np.float64(42.72799999999986)},\n",
       " {'score': np.float64(42.77799999999986)},\n",
       " {'score': np.float64(42.82599999999986)},\n",
       " {'score': np.float64(42.875999999999856)},\n",
       " {'score': np.float64(42.92599999999985)},\n",
       " {'score': np.float64(42.97599999999985)},\n",
       " {'score': np.float64(43.02599999999985)},\n",
       " {'score': np.float64(43.075999999999844)},\n",
       " {'score': np.float64(44.12599999999984)},\n",
       " {'score': np.float64(44.17599999999984)},\n",
       " {'score': np.float64(44.225999999999836)},\n",
       " {'score': np.float64(44.27599999999983)},\n",
       " {'score': np.float64(44.32599999999983)},\n",
       " {'score': np.float64(44.37599999999983)},\n",
       " {'score': np.float64(44.425999999999824)},\n",
       " {'score': np.float64(44.47599999999982)},\n",
       " {'score': np.float64(45.52599999999982)},\n",
       " {'score': np.float64(45.575999999999816)},\n",
       " {'score': np.float64(45.62599999999981)},\n",
       " {'score': np.float64(45.67599999999981)},\n",
       " {'score': np.float64(45.72599999999981)},\n",
       " {'score': np.float64(45.775999999999804)},\n",
       " {'score': np.float64(45.8259999999998)},\n",
       " {'score': np.float64(45.8759999999998)},\n",
       " {'score': np.float64(45.925999999999796)},\n",
       " {'score': np.float64(45.97599999999979)},\n",
       " {'score': np.float64(46.02599999999979)},\n",
       " {'score': np.float64(46.07599999999979)},\n",
       " {'score': np.float64(46.125999999999785)},\n",
       " {'score': np.float64(46.17599999999978)},\n",
       " {'score': np.float64(46.22599999999978)},\n",
       " {'score': np.float64(46.275999999999776)},\n",
       " {'score': np.float64(46.31799999999978)},\n",
       " {'score': np.float64(46.361999999999775)},\n",
       " {'score': np.float64(46.407999999999774)},\n",
       " {'score': np.float64(46.455999999999776)},\n",
       " {'score': np.float64(46.50599999999977)},\n",
       " {'score': np.float64(46.55599999999977)},\n",
       " {'score': np.float64(46.60599999999977)},\n",
       " {'score': np.float64(46.655999999999764)},\n",
       " {'score': np.float64(46.70599999999976)},\n",
       " {'score': np.float64(46.75599999999976)},\n",
       " {'score': np.float64(46.805999999999756)},\n",
       " {'score': np.float64(47.85599999999975)},\n",
       " {'score': np.float64(47.90599999999975)},\n",
       " {'score': np.float64(47.95599999999975)},\n",
       " {'score': np.float64(48.005999999999744)},\n",
       " {'score': np.float64(48.05599999999974)},\n",
       " {'score': np.float64(48.10599999999974)},\n",
       " {'score': np.float64(48.155999999999736)},\n",
       " {'score': np.float64(49.20599999999973)},\n",
       " {'score': np.float64(49.25599999999973)},\n",
       " {'score': np.float64(49.30599999999973)},\n",
       " {'score': np.float64(49.355999999999725)},\n",
       " {'score': np.float64(49.40599999999972)},\n",
       " {'score': np.float64(49.45599999999972)},\n",
       " {'score': np.float64(49.505999999999716)},\n",
       " {'score': np.float64(50.55599999999971)},\n",
       " {'score': np.float64(50.60599999999971)},\n",
       " {'score': np.float64(50.65599999999971)},\n",
       " {'score': np.float64(50.705999999999705)},\n",
       " {'score': np.float64(50.7559999999997)},\n",
       " {'score': np.float64(50.8059999999997)},\n",
       " {'score': np.float64(50.855999999999696)},\n",
       " {'score': np.float64(50.90599999999969)},\n",
       " {'score': np.float64(50.95599999999969)},\n",
       " {'score': np.float64(51.00599999999969)},\n",
       " {'score': np.float64(51.055999999999685)},\n",
       " {'score': np.float64(51.10599999999968)},\n",
       " {'score': np.float64(51.15599999999968)},\n",
       " {'score': np.float64(51.205999999999676)},\n",
       " {'score': np.float64(51.25599999999967)},\n",
       " {'score': np.float64(51.30599999999967)},\n",
       " {'score': np.float64(51.35599999999967)},\n",
       " {'score': np.float64(51.35599999999967)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7349b320-4991-4cb2-b12d-1ba3c6e3bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_board(board,text=None):\n",
    "    plt.figure(figsize=(2,2))\n",
    "    plt.imshow(board)\n",
    "    plt.axis('off')\n",
    "    if text is not None:\n",
    "        plt.gca().text(3, 3, text, fontsize=45,color = 'yellow')\n",
    "    #plt.savefig(file_name,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc01cb5-7ea7-4506-a645-25662386fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = SnakeGame(width=14, height = 14, border = 1)\n",
    "board,reward,done,info = game.reset()\n",
    "a = {'forw': 0, 'left': -1, 'right': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc82b15-4741-4266-828f-00d67422312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    'board': [],\n",
    "    'reward': [],\n",
    "    'done': -1,\n",
    "    'info': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6729db1f-20a3-4eba-a87f-e7a45006b9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAj9JREFUeJzt3TGOg0AQAMHj5H8DL18HDi/Zs0DQdlWMVhO0JlkByxhj/EDM79UDwDuES5JwSRIuScIlSbgkCZck4ZIkXJIesw9u23biGPAy25mNS5JwSRIuScIlSbgkCZck4ZIkXJKES9L0zdmsfd+PPpIPsK7roefZuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiXpcfUAn2yMMffgspw7yJvuOdWLjUuScEkSLknCJUm4JAmXJOGSJFyShEuSm7MTLTe9EfsENi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiXJqzvfaPJbfHf+6p2NS5JwSRIuScIlSbgkCZck4ZIkXJKES5Kbs2904xuxWTYuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZJ0+F931nU9+kj4w8YlSbgkCZck4ZIkXJKES5JwSRIuScIlaRljjKuHgP+ycUkSLknCJUm4JAmXJOGSJFyShEuScEl6AmXiFOItyEFSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbe979d9-9e31-45a4-ad4c-4ddc9e2b6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "board,reward,done,info = game.step(a['left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310e7cef-50a3-424c-900b-512f6e970131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkNJREFUeJzt3TFqw0AQQNEo+N6STr4pUobAJkiWv/xebZYpPtMMyMsYY3xAzOfVA8B/CJck4ZIkXJKES5JwSRIuScIlSbgkPWZ/uG3biWPAt9nObFyShEuScEkSLknCJUm4JAmXJOGSJFySpi9ns/Z9P/pJbmBd10Pfs3FJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0uPqAe5sXD3AL5arBziAjUuScEkSLknCJUm4JAmXJOGSJFyShEuSy9mZxtztbFnucMt6LhuXJOGSJFyShEuScEkSLknCJUm4JAmXJJezE7mIncfGJUm4JAmXJOGSJFyShEuScEkSLkkOEO9o9mt8L3w/sXFJEi5JwiVJuCQJlyThkiRckoRLknBJcjl7Ry98EZtl45IkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSYf/6866rkc/CT/YuCQJlyThkiRckoRLknBJEi5JwiVJuCQtY4xx9RDwVzYuScIlSbgkCZck4ZIkXJKES5JwSRIuSV8r9BTl2dHR8wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf3af36-d8c6-4824-bbf9-c15369bf7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "board,reward,done,info = game.step(a['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71a286c5-be50-42b9-9cd7-2b804349ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkZJREFUeJzt3bFugzAUQNFS5b8hX+4OHbu4iMi54ZwZGQ9Xb3kSbGOM8QUx36svAGcIlyThkiRckoRLknBJEi5JwiVJuCQ9Zh88juOF14Bfs52ZuCQJlyThkiRckoRLknBJEi5JwiVJuCRNb85mPZ/Pq4/kA+z7ful5Ji5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJeqy+wCcbC965LXjnCiYuScIlSbgkCZck4ZIkXJKES5JwSRIuSTZnJ4wxuRPb5vZYd9l2XcnEJUm4JAmXJOGSJFyShEuScEkSLknCJcnm7IRtciPG65i4JAmXJOGSJFyShEuScEkSLknCJckC4o5mv8b3xnsWE5ck4ZIkXJKES5JwSRIuScIlSbgkCZckm7M7euON2CwTlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJuvyvO/u+X30k/GHikiRckoRLknBJEi5JwiVJuCQJlyThkrSNMcbqS8B/mbgkCZck4ZIkXJKES5JwSRIuScIlSbgk/QBIqxXkpABFlAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74b10d35-c8a7-41e8-81da-b142ca74d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "board,reward,done,info = game.step(a['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a7f5a2d-d256-467f-aff3-7f7d381ef953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkVJREFUeJzt3bFugzAUQFGo8t/Al7tDt3SolYDIrc6ZkeXh6i1PFusYYywQ83X3BeAVwiVJuCQJlyThkiRckoRLknBJEi5Jj9kP932/8BrwY7YzE5ck4ZIkXJKES5JwSRIuScIlSbgkCZek6c3ZrOM4zj6Sf2DbtlPPM3FJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0uPuC3yaMfHNevkt+IuJS5JwSRIuScIlSbgkCZck4ZIkXJKES5LN2QtmtmvLYsN2JROXJOGSJFyShEuScEkSLknCJUm4JAmXJJuzZ2NiL7baid3NxCVJuCQJlyThkiRckoRLknBJEi5JFhBPVsuFBBOXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSdM/THb+t4U0mLknCJUm4JAmXJOGSJFyShEuScEkSLkn3bM5sxHiTiUuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEk6/enOtm1nHwm/mLgkCZck4ZIkXJKES5JwSRIuScIlSbgkrWOM2Z83wccwcUkSLknCJUm4JAmXJOGSJFyShEuScEn6BlAdFea0Qjw4AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c42413-d17d-4e22-a43c-c0b4cd51fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "board,reward,done,info = game.step(a['forw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69da254d-a4cb-48c7-a0c2-cd99209c188e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkBJREFUeJzt3bFqwzAUQNG65L/lfLk6dCqlIFoV5ybnzEZouLzlIXzMOecbxLxffQH4DeGSJFyShEuScEkSLknCJUm4JAmXpNvqh+d5/uM14NNqZyYuScIlSbgkCZck4ZIkXJKES5JwSRIuScubs1X3+333kTyBMcbW80xckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRL0u3qCzyaufGsY+NZfGXikiRckoRLknBJEi5JwiVJuCQJlyThkvQym7M5F3dih31XgYlLknBJEi5JwiVJuCQJlyThkiRckl5mAXFYLDwVE5ck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZJ0zdOd1V/beG3DD0xckoRLknBJEi5JwiVJuCQJlyThkiRckq7ZnNmI8UcmLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJWn7050xxu4j4RsTlyThkiRckoRLknBJEi5JwiVJuCQJl6Rjzrn68yZ4GCYuScIlSbgkCZck4ZIkXJKES5JwSRIuSR+USBXjpu9KvgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef454287-9b45-4a8e-ba27-744a31db2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "board,reward,done,info = game.step(a['forw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182c289c-d5c9-4c4d-bb0c-2e4816300bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAkJJREFUeJzt3cFKxDAUQFEr89/pfHlcCIKIkJEO8eo56yEp5fI2IZ1jzjlfIOZ19wPATwiXJOGSJFyShEuScEkSLknCJUm4JN1Wf3ie5xMfA96tdmbikiRckoRLknBJEi5JwiVJuCQJlyThkrR8crbqfr9fvSR/wBjj0vVMXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuSbcdm84Nex4b9uR5TFyShEuScEkSLknCJUm4JAmXJOGStOUAYpVDA75j4pIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJL2XN2Zi18PO1ze+bD6wbV/8spMXJKES5JwSRIuScIlSbgkCZck4ZIkXJK2nJwdTsQe55V9YuKSJFyShEuScEkSLknCJUm4JAmXJOGSJFyShEuScEkSLknCJUm4JAmXJOGSJFySLr+6M8a4ekn4wsQlSbgkCZck4ZIkXJKES5JwSRIuScIl6Zhz9b+b4PcwcUkSLknCJUm4JAmXJOGSJFyShEuScEl6AyIjFOO6RiPnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_board(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01e02526-8f82-40cc-af1f-912673d45c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72183467-64a3-4a99-98a4-b743404a2061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
